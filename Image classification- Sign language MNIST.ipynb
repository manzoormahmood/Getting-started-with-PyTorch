{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is PyTorch?\n",
    "* Its a machine learning library used for NLP, computer vision,etc.\n",
    "* Provides Tensor computing with GPU support.\n",
    "\n",
    "# Modules in Pytorch\n",
    "*  **Autograd module:**\n",
    "PyTorch uses a method called automatic differentiation. A recorder records what operations have performed, and then it replays it backward to compute the gradients. This method is especially powerful when building neural networks to save time on one epoch by calculating differentiation of the parameters at the forward pass.\n",
    "\n",
    "* **Optim module:**\n",
    "torch.optim is a module that implements various optimization algorithms used for building neural networks. \n",
    "\n",
    "* **nn module:**\n",
    "PyTorch autograd makes it easy to define computational graphs and take gradients, but raw autograd can be a bit too low-level for defining complex neural networks. This is where the nn module can help.\n",
    "\n",
    "# Topics covered in this notebook\n",
    "* Handwritten Digits Classification (Numerical Data)-**Digit MNIST**\n",
    "* Objects Image Classification (Image Data, CNN)-**Sign Language MNIST**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objects Image Classification (Image Data, CNN)-Sign Language MNIST\n",
    "### Importing lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import math\n",
    "%matplotlib inline\n",
    "import time\n",
    "\n",
    "#pytorch utility imports\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "#neural net imports\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "start = torch.cuda.Event(enable_timing=True) #time measure during cuda training\n",
    "end = torch.cuda.Event(enable_timing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('../input/sign-language-mnist/sign_mnist_test/sign_mnist_test.csv')\n",
    "train_df = pd.read_csv('../input/sign-language-mnist/sign_mnist_train/sign_mnist_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((train_df['label'].unique()).shape )# There are 24 possible labels, 9=J and 25=Z require motion so they are absent.\n",
    "print(np.sort(train_df['label'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separating labels and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_df['label'].values\n",
    "test_labels=test_df['label'].values\n",
    "train_images = (train_df.iloc[:,1:].values).astype('float32')\n",
    "test_images = (test_df.iloc[:,1:].values).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train images shape\",train_images.shape)\n",
    "print(\"train labels shape\",train_labels.shape)\n",
    "print(\"test images shape\",test_images.shape)\n",
    "print(\"test labels shape\",test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape features\n",
    "*Note: For images reshape will be in 4D*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape(train_images.shape[0],1, 28, 28)\n",
    "test_images = test_images.reshape(test_images.shape[0],1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_images.shape)\n",
    "print(test_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing to Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_tensor = torch.tensor(train_images)/255.0 #default torch.FloatTensor\n",
    "train_labels_tensor = torch.tensor(train_labels)\n",
    "train_tensor = TensorDataset(train_images_tensor, train_labels_tensor)\n",
    "\n",
    "test_images_tensor = torch.tensor(test_images)/255.0\n",
    "test_labels_tensor = torch.tensor(test_labels)\n",
    "test_tensor = TensorDataset(test_images_tensor, test_labels_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_tensor, batch_size=16, num_workers=2, shuffle=True)\n",
    "test_loader = DataLoader(test_images_tensor, batch_size=16, num_workers=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "from torch.optim import Adam, SGD\n",
    "\n",
    "class Net(nn.Module):                                           # class Net inherits from predefined Module class in torch.nn\n",
    "    def __init__(self):                                         # calling constructor of  parent class\n",
    "        super().__init__()                                     \n",
    "        \n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1,32,3)              # 2d convolution layer : (input : 1 image , output : 32 channels , kernel size : 3*3)\n",
    "        self.conv2 = nn.Conv2d(32,64,3)\n",
    "        self.conv3 = nn.Conv2d(64,128,3)\n",
    "        \n",
    "        self.linear_in = None                      # used to calculate input of first linear layer by passing fake data through 2d layers\n",
    "        x = torch.rand(28,28).view(-1,1,28,28)     # using convs function\n",
    "        self.convs(x)\n",
    "    \n",
    "        self.fc1 = nn.Linear(self.linear_in,512)\n",
    "        self.fc2 = nn.Linear(512,26)\n",
    "        \n",
    "    def convs(self,x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)) , (2,2) )      # relu used for activation function \n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)) , (2,2) )      # max_pool2d for max pooling results of each kernel with window size 2*2\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)) , (2,2) )\n",
    "        \n",
    "        if self.linear_in == None:\n",
    "            self.linear_in = x[0].shape[0]*x[0].shape[1]*x[0].shape[2]  # input of first linear layer is multiplication of dimensions of ouput \n",
    "        return x                                                        # tensor of the 2d layers\n",
    "    \n",
    "    def forward(self,x):                                    # forward pass function uses the convs function to pass through 2d layers\n",
    "        x = self.convs(x)\n",
    "        x = x.view(-1,self.linear_in)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = F.log_softmax(x ,dim = -1)                     # log_softmax for finding output neuron with highest value\n",
    "        return x\n",
    "    \n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "if (device.type=='cuda'):\n",
    "    model.cuda() # CUDA\n",
    "\n",
    "net.to(device)\n",
    "\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (device.type=='cuda'):\n",
    "    start.record() \n",
    "    \n",
    "loss_log = []\n",
    "for epoch in range(20): # loop over dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, (data,target) in enumerate(train_loader):\n",
    "\n",
    "        \n",
    "        if (device.type=='cuda'):\n",
    "            inputs,labels= Variable(data.cuda()), Variable(target.cuda())\n",
    "        else:\n",
    "            inputs,labels= Variable(data), Variable(target)\n",
    "       \n",
    "        \n",
    "        \n",
    "        # zero parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        loss =  F.cross_entropy(outputs, labels)\n",
    "        #print(loss)\n",
    "        \n",
    "   \n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "      \n",
    "        #if i % 100 == 1:\n",
    "        print('\\r Train Epoch: {} [{}/{} ({:.0f}%)] \\tLoss: {:.6f}'.format( epoch, i * len(data), len(train_loader.dataset),\n",
    "                                                                           100. * i / len(train_loader), loss.data), end='')\n",
    "        \n",
    "    print(\"\")\n",
    "                \n",
    "print('Finished Training')\n",
    "if (device.type=='cuda'):\n",
    "    end.record()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (device.type=='cuda'):\n",
    "    evaluate_x=test_images_tensor.cuda()\n",
    "    evaluate_y=test_labels_tensor.cuda()\n",
    "else:\n",
    "    evaluate_x=test_images_tensor\n",
    "    evaluate_y=test_labels_tensor\n",
    "    \n",
    "\n",
    "output = net(evaluate_x)\n",
    "\n",
    "pred = output.data.max(1)[1]\n",
    "d = pred.eq(evaluate_y.data).cpu()\n",
    "a=(d.sum().data.cpu().numpy())\n",
    "b=d.size()\n",
    "b=torch.tensor(b)\n",
    "b=(b.sum().data.cpu().numpy())\n",
    "accuracy = a/b\n",
    "\n",
    "print('Accuracy:', accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (device.type=='cuda'):\n",
    "    torch.cuda.synchronize()\n",
    "    print(start.elapsed_time(end)/1000,\"sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(\"f1 score =\",f1_score(test_labels, pred.cpu().numpy(), average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Lets get connected on [Linkedin](https://www.linkedin.com/in/manzoor-bin-mahmood/)\n",
    "\n",
    "Visit my [website](https://manzoormahmood.github.io/) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
