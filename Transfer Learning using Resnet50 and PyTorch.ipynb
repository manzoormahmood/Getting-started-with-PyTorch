{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Getting started with Transfer Learning\n\n### Do Upvote this notebook if you like my work.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## What is transfer learning?\nTransfer learning is a machine learning technique where a model trained on one task is modified for a second related task. Like a model trained on a large number of images can be used with slight modifications for new datasets. \n\nThe pre-trained model should be chosen very carefully meaning model trained on image dataset cannot be used for an audio dataset.\n\nTransfer learning can be used when a sufficient amount of training data is not available or large processing resource is not available.\n\n\n## Aim of this notebook\nIn this notebook dogs and classification is done using transfer learning. The Resnet50 model has been used. This model can be used easily from PyTorch. All architecture except the last layer is fixed. The last layer is modified for two classes. With very less epoch very good accuracy can be achieved.\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Importing libraries","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\n%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport torch\nfrom torchvision import datasets, models, transforms\nimport torch.nn as nn\nfrom torch.nn import functional as F\nimport torch.optim as optim\nimport torchvision\n\ninput_path = \"../input/cat-and-dog/\" ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                 std=[0.229, 0.224, 0.225])\n\ndata_transforms = {\n    'train':\n    transforms.Compose([\n        transforms.Resize((224,224)),\n        transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        normalize\n    ]),\n    'validation':\n    transforms.Compose([\n        transforms.Resize((224,224)),\n        transforms.ToTensor(),\n        normalize\n    ]),\n}\n\nimage_datasets = {\n    'train': \n    datasets.ImageFolder(input_path + 'training_set/training_set', data_transforms['train']),\n    'validation': \n    datasets.ImageFolder(input_path + 'test_set/test_set', data_transforms['validation'])\n}\n\ndataloaders = {\n    'train':\n    torch.utils.data.DataLoader(image_datasets['train'],\n                                batch_size=32,\n                                shuffle=True,\n                                num_workers=0),  # for Kaggle\n    'validation':\n    torch.utils.data.DataLoader(image_datasets['validation'],\n                                batch_size=32,\n                                shuffle=False,\n                                num_workers=0)  # for Kaggle\n}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Selecting GPU if available","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndevice","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = models.resnet50(pretrained=True).to(device)\n    \nfor param in model.parameters():\n    param.requires_grad = False   \n    \nmodel.fc = nn.Sequential(\n               nn.Linear(2048, 128),\n               nn.ReLU(inplace=True),\n               nn.Linear(128, 2)).to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.fc.parameters())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Training","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(model, criterion, optimizer, num_epochs=3):\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n        print('-' * 10)\n\n        for phase in ['train']:\n            if phase == 'train':\n                model.train()\n            else:\n                model.eval()\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n\n                if phase == 'train':\n                    optimizer.zero_grad()\n                    loss.backward()\n                    optimizer.step()\n\n                _, preds = torch.max(outputs, 1)\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            epoch_loss = running_loss / len(image_datasets[phase])\n            epoch_acc = running_corrects.double() / len(image_datasets[phase])\n\n            print('{} loss: {:.4f}, acc: {:.4f}'.format(phase,\n                                                        epoch_loss,\n                                                        epoch_acc))\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_trained = train_model(model, criterion, optimizer, num_epochs=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!mkdir models\n!mkdir models/pytorch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.save(model_trained.state_dict(), 'models/pytorch/weights.h5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Modifying last layer","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model = models.resnet50(pretrained=False).to(device)\nmodel.fc = nn.Sequential(\n               nn.Linear(2048, 128),\n               nn.ReLU(inplace=True),\n               nn.Linear(128, 2)).to(device)\nmodel.load_state_dict(torch.load('models/pytorch/weights.h5'))\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Showing some sample images","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_img_paths = [\"test_set/test_set/cats/cat.4001.jpg\",\n                        \"test_set/test_set/cats/cat.4003.jpg\",\n                        \"test_set/test_set/dogs/dog.4004.jpg\",\n                       \"test_set/test_set/dogs/dog.4006.jpg\"]\nimg_list = [Image.open(input_path + img_path) for img_path in validation_img_paths]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_batch = torch.stack([data_transforms['validation'](img).to(device)\n                                for img in img_list])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_logits_tensor = model(validation_batch)\npred_logits_tensor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_probs = F.softmax(pred_logits_tensor, dim=1).cpu().data.numpy()\npred_probs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(1, len(img_list), figsize=(20, 5))\nfor i, img in enumerate(img_list):\n    ax = axs[i]\n    ax.axis('off')\n    ax.set_title(\"{:.0f}% Cat, {:.0f}% Dog\".format(100*pred_probs[i,0],\n                                                            100*pred_probs[i,1]))\n    ax.imshow(img)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Confusion Matrix","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"labels_input=[]\nlabels_output=[]\ndef test_model(model, criterion, optimizer, num_epochs=1):\n    for phase in ['validation']:\n        model.eval()\n\n        running_loss = 0.0\n        running_corrects = 0\n\n        for inputs, labels in dataloaders[phase]:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            labels_input.append(labels)\n\n            outputs = model(inputs)\n            \n            loss = criterion(outputs, labels)\n            _, preds = torch.max(outputs, 1)\n            \n            labels_output.append(preds)\n            \n            \ntest_model(model, criterion, optimizer, num_epochs=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred=(torch.cat(labels_output))\ny_pred=y_pred.cpu().numpy()\n\n\ny_true=(torch.cat(labels_input))\ny_true=y_true.cpu().numpy()\n\n\nfrom sklearn.metrics import confusion_matrix\nconfusion_matrix(y_true, y_pred)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}